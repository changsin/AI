{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsin/AI/blob/main/08.4.decision_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HclJutxS2bYj"
      },
      "source": [
        "# Decision Tree\n",
        "\n",
        "The following is an explanation of Decision Tree (8.4) in Ertel's Artificial Intelligence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oFEJiGK0ZwY"
      },
      "source": [
        "## Entropy\n",
        "\n",
        "The entropy is calculated according to Shannon's formula:\n",
        "\n",
        "$ H(p) = H(p_1;...p_n) = -\\Sigma_{n=1}^{n}p_i log_2 p_i = H(D) $\n",
        "\n",
        "Applied to the skiing example in the text book, we calculate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNlVpQa2mVhN"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hQBW-9ork94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13338926-e373-4016-c11e-44bccace79d7"
      },
      "source": [
        "p1 = 5/11\n",
        "p2 = 6/11\n",
        "p3 = 7/11\n",
        "\n",
        "probs = np.array([p1, p2])\n",
        "\n",
        "def calculate_entropy(probs):\n",
        "  entropy = 0\n",
        "  for p in probs:\n",
        "    if p != 0:\n",
        "      entropy += p*np.log2(p)\n",
        "  \n",
        "  return -entropy\n",
        "\n",
        "\n",
        "\n",
        "H = -(p1*np.log2(p1)) - (p2*np.log2(p2))\n",
        "H\n",
        "\n",
        "calculate_entropy(probs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9940302114769565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5ItFMaGdmjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54caf576-0a60-4c3f-bfcd-a3125a389772"
      },
      "source": [
        "calculate_entropy(np.array([2/7, 5/7]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.863120568566631"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUMuUsBAj3HZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a74610e-fc41-40a2-d4a9-3174c8be5487"
      },
      "source": [
        "calculate_entropy(np.array([4/4, 0/4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYI4IgstkfDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9953553-8b50-4287-ff12-5b7edd74f77d"
      },
      "source": [
        "calculate_entropy(np.array([6/11, 5/11]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9940302114769565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEJK8GTX2FgC"
      },
      "source": [
        "## Information Gain\n",
        "\n",
        "For dataset D, the information gained is thus:\n",
        "\n",
        "$$ I(D) = 1 - H(D) $$\n",
        "\n",
        "The information gain through attribute A is defined as:\n",
        "$$ G(D, A) = \\Sigma_{i=1}^{n}\\frac{|D_i|}{|D|}I(D_i) - I(D) $$\n",
        "\n",
        "or if we rewrite it in terms of entropy:\n",
        "\n",
        "$$ = H(D) - \\Sigma_{i=1}^{n}\\frac{|D_i|}{|D|}H(D_i) $$\n",
        "\n",
        "Applied to our skiing example, for the choice of snow distribution, we get:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9zs5opWrKGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cfd4cb8-e617-4ea9-f59c-f73d899bb72a"
      },
      "source": [
        "D = 11\n",
        "D_snow_little = 4\n",
        "D_snow_big = 7\n",
        "H_D = calculate_entropy(np.array([6/11, 5/11]))\n",
        "H_snow_little = calculate_entropy(np.array([4/4, 0/4]))\n",
        "H_snow_big = calculate_entropy(np.array([2/7, 5/7]))\n",
        "H_snow_big"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.863120568566631"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NuMkVGr14g4"
      },
      "source": [
        "0.863 is the entropy we get when we branch the decision tree for snow distribution. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRc9s5NjlwhL"
      },
      "source": [
        "def calculate_information_gain(dataset_count, initial_entropy, subs):\n",
        "  \"\"\"\n",
        "    dataset_count: total number of entries in the dataset\n",
        "    initial_entropy: the initial entropy of the dataset\n",
        "    subs: a list of positive and negative counts for each sub-branch:\n",
        "      e.g., [[4, 0], [2, 5]]\n",
        "  \"\"\"\n",
        "  sub_entropy = 0\n",
        "\n",
        "  for sub in subs:\n",
        "    sub_counts = np.array(sub)\n",
        "    sub_total = np.sum(sub_counts)\n",
        "    sub_probs = np.array([ di/sub_total for di in sub_counts])\n",
        "\n",
        "    entropy = calculate_entropy(sub_probs)\n",
        "    print(\"subentropy\", entropy)\n",
        "\n",
        "    sub_entropy += (sub_total/dataset_count)*entropy\n",
        "\n",
        "  return initial_entropy - sub_entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SATgMWe71Tsj"
      },
      "source": [
        "# How to build a decision tree with information gain metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LipppCdD04YR"
      },
      "source": [
        "Using the information gain formula, we can now calculate and compare what is the best way to build a decision tree. Given there are three attributes, we calculate the information gain for each as follows.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqZzohnm1S7h"
      },
      "source": [
        "### A1: Snow distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2Oew6GM026M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f2d1a3f-f61f-42f9-b10a-8f846d09a86d"
      },
      "source": [
        "H_D = calculate_entropy(np.array([6/11, 5/11]))\n",
        "sub_snow = [[4, 0],\n",
        "            [2, 5]]\n",
        "calculate_information_gain(11, H_D, sub_snow)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subentropy -0.0\n",
            "subentropy 0.863120568566631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44477166784364586"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e546ow3h2cWo"
      },
      "source": [
        "### A2: Weekend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZZalp3mpazt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f8715c-1ba0-409a-858a-558795bf565d"
      },
      "source": [
        "sub_weekend = [[5, 2],\n",
        "               [1, 3]]\n",
        "calculate_information_gain(11, H_D, sub_weekend)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subentropy 0.863120568566631\n",
            "subentropy 0.8112781244591328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14976144076759756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBZNWVgw2kaU"
      },
      "source": [
        "### A3: Sun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7cryB1YreL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3e4b52-ba3f-45f1-8050-54ebc8e6794d"
      },
      "source": [
        "sub_sun = [[5, 3],\n",
        "            [1, 2]]\n",
        "calculate_information_gain(11, H_D, sub_sun)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subentropy 0.9544340029249649\n",
            "subentropy 0.9182958340544896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0494520727893939"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scJoerE52oLI"
      },
      "source": [
        "Based on the results, we know that snow distribution is the first branch question we should ask to get the most information gain."
      ]
    }
  ]
}
