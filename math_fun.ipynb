{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Session_1_1: (BLANK) Linear regression",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsin/AI/blob/main/math_fun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o68CszJ-uyw-"
      },
      "source": [
        "# Algebraic Playground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnwXnbr4m8I9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.linspace(1, 224, 1000)\n",
        "y = []\n",
        "for x1 in x:\n",
        "  # print(x1)\n",
        "  # y.append(np.clip(np.random.chisquare(x1, 1), 0, IMAGE_SIZE))\n",
        "  noise = np.clip(np.random.noncentral_chisquare(IMAGE_SIZE/2, 50, 4), 0, IMAGE_SIZE)\n",
        "\n",
        "  y.append(np.clip(np.random.noncentral_chisquare(IMAGE_SIZE/2, 50, 2), 0, IMAGE_SIZE))\n",
        "  # y.append(np.clip(np.random.normal(loc=x1, scale=50, size=1), 0, IMAGE_SIZE))\n",
        "\n",
        "# y_line = -2.1*x_line + 20\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x, y, 'g', label='y=wx+b')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znoi-4Y5_znK"
      },
      "source": [
        "## (0) Introduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqypE4Lrp8Qm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802efa18-8de0-4431-efb0-852258152156"
      },
      "source": [
        "!pip install d2l==0.16.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting d2l==0.16.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/1f/13de7e8cafaba15739caee0596032412aaf51a22726649b317bdb53c4f9a/d2l-0.16.2-py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 21.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 15.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 71kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.2) (1.1.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (7.6.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.3.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (5.0.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.2) (4.10.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.2) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.2) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.2) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.2) (2.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.2) (2020.12.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l==0.16.2) (2018.9)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (2.11.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (4.7.1)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (5.1.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.4.4)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (5.0.5)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (3.3.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.2) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l==0.16.2) (1.0.18)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l==0.16.2) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->d2l==0.16.2) (5.3.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.2) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.2) (3.5.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (5.1.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (0.9.4)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (1.5.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.2) (0.2.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.16.2) (1.9.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.16.2) (22.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->d2l==0.16.2) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert->jupyter->d2l==0.16.2) (1.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert->jupyter->d2l==0.16.2) (2.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.16.2) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.16.2) (20.9)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l==0.16.2) (0.2.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l==0.16.2) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l==0.16.2) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l==0.16.2) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l==0.16.2) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->d2l==0.16.2) (54.2.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.16.2) (0.7.0)\n",
            "Installing collected packages: d2l\n",
            "Successfully installed d2l-0.16.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oSKBrPovFTw"
      },
      "source": [
        "In this part, we will look into the necessary building blocks of common Machine learning code. We will illustrate how these blocks work together using a simple, but widely used, model.\n",
        "\n",
        "Let's assume we want to predict some house prices. A simple model that can be used to generate some useful insights could be the following simple **Linear regression model**:\n",
        "\n",
        "$$\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b.$$\n",
        "\n",
        "This is equivalent to:\n",
        "\n",
        "$$\\hat{y} = w_1  x_1 + ... + w_d  x_d + b.$$ and $$\\hat{y} = \\mathbf{X} \\mathbf{w} + b.$$\n",
        "\n",
        "Let's first import the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqugOa7_vTH6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW_qk8Jjy684"
      },
      "source": [
        "## (1) Generating the synthetic dataset\n",
        "\n",
        "We want to generate 1'000 datapoints where the true model parameters are $\\textbf{w} = [2, -3.4]$ and $b = 4.2$. Additionally, we will add a **noise term $\\epsilon$** since we would like to simulate the imperfect process of data collection. The noise will follow a **Gaussian/Normal distribution** with mean $0$ and varianve of $.01$. The data will be created using the following equation:\n",
        "\n",
        "$$\\mathbf{y}= \\mathbf{X} \\mathbf{w} + b + \\mathbf\\epsilon$$\n",
        "\n",
        "Let's define the function which will generate this data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFDeXMku11sD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccIx7hVr4Rjj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YXeh2QK48js"
      },
      "source": [
        "Let's check the first datapoint the correlation by plotting all the datapoints\n",
        ":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU_z27DO4a7V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynIgeRwz6hMd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtjmohM9_s_5"
      },
      "source": [
        "## (2) Iterating over the minibatches batches\n",
        "\n",
        "Now that we have the dataset, we need a method to iterate over it to generate minibatches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPJAri5nAOvh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q54Ei0PWBlkx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k5qQcyNCH9R"
      },
      "source": [
        "This method uses an iterator, but it is really inefficient! We will see a better way to do the batch sampling in this session using PyTorch's custom class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrhQyJjSCQbF"
      },
      "source": [
        "## (3) Defining the model and initialize the model parameters\n",
        "\n",
        "We are going to define the model and initialize the model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz5Od5meEZGn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXYUTq4QHjFW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZC1eaXNJ50Z"
      },
      "source": [
        "## (4) Defining the loss function\n",
        "\n",
        "We need a loss function so that we can calculate the gradient of the losses, letting us update the model in the correct direction. Here, we will use a squared loss function. The mathematical expression is given by:\n",
        "\n",
        "$$l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2.$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIVM5KcQLTfe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXH9sSLGL36F"
      },
      "source": [
        "## (5) Defining the optimization algorithm\n",
        "\n",
        "Next, we describe how to update the parameters of the model (the $\\textbf{w}$ of our model). \n",
        "\n",
        "The most straightforward and commonly used algorithm is called **Stochastic Gradient Descent**\n",
        "\n",
        "$$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b).$$\n",
        "\n",
        "The algorithm does the following two steps:\n",
        "(1) Initialize the values of the model parameters, typically at random;\n",
        "(2) Iteratively sample random minibatches from the data,\n",
        "updating the parameters in the direction of the negative gradient.\n",
        "For quadratic losses and affine transformations,\n",
        "we can write it as follows:\n",
        "\n",
        "$$\\begin{aligned} \\mathbf{w} &\\leftarrow \\mathbf{w} -   \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{\\mathbf{w}} l^{(i)}(\\mathbf{w}, b) = \\mathbf{w} - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\mathbf{x}^{(i)} \\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right),\\\\ b &\\leftarrow b -  \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_b l^{(i)}(\\mathbf{w}, b)  = b - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right). \\end{aligned}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy0-1yMXL3g5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3MAslymQsTa"
      },
      "source": [
        "## (6) Training the model\n",
        "\n",
        "Let's define the training loop of the model. This is where all the magic happens!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8J78qq_Q8IN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exp7yqC5RImR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nsgnPLmTEAY"
      },
      "source": [
        "## (7) Testing the model\n",
        "\n",
        "We know the true parameters (since we created the data) and we can compare the obtained parameters to these ground-truths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA2xWWoZTOfj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK92hgtXvuCh"
      },
      "source": [
        "# Session 1: No need to reinvent the wheel! Concise implementation of the linear regression model\n",
        "\n",
        "In the last sections, we have seen how to set up a simple experiment:\n",
        "\n",
        "* Load / create dataset\n",
        "* Initialize a dataloader\n",
        "* Initialize model\n",
        "* Initialize the optimization algorithm\n",
        "* Initialize the loss-metric\n",
        "* Train the model/ testing the model \n",
        "\n",
        "There are important aspects that we haven't talked about yet (and that we will probably touch upon in later sessions)\n",
        "\n",
        "* How to pre-process the data / features\n",
        "* How to do proper train / validation / test data splits\n",
        "\n",
        "Another important point is that todays frameworks (PyTorch, TF/Keras, mtnext) offer plenty of pre-implemented classes and tools. We don't need to reinvent the wheel every single time. \n",
        "\n",
        "Let's see how to simplify the above experiment using the PyTorch framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHbte2kR0thS"
      },
      "source": [
        "# Let's import the important modules\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJuFs6bb2WlD"
      },
      "source": [
        "## (1) Getting the data and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtuxPjAY1BC0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npYlgs6U1fZO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9JVTazF1-mm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjOv1DaY2Jto"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6Ex6bt24B27"
      },
      "source": [
        "## (2) Defining the model and initializing the parameters\n",
        "\n",
        "In PyTorch, defining model architectures and initializing the parameters is a breeze! We just need the following three commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0YsQxmQ4Rud"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAS7OYms58lL"
      },
      "source": [
        "## (3) Defining the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIF1qwmD5_pq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td1G_VWD6I4q"
      },
      "source": [
        "## (4) Defining the optimization algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKa596Go6MJf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n05K5Tdz6gV_"
      },
      "source": [
        "## (5) Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riYU-TS17Xhi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qgAUuRP8JEv"
      },
      "source": [
        "## (6) Checking the model parameters\n",
        "\n",
        "Now that the model is trained, we should check if the parameters have been correctly predicted:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thQfTMVf8Rb6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbwDdCbC8sGT"
      },
      "source": [
        "We can recreate the same code with only a few lines using the PyTorch framework. Frameworks allow us to concentrate on the interesting parts of the issues at hand and provide useful functions/classes to quickly run experiments!"
      ]
    }
  ]
}