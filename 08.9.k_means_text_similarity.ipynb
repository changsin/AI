{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsin/AI/blob/main/08.9.k_means_text_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cRQDw8gYaa6"
      },
      "source": [
        "# K Means Clustering for Text Similarity\n",
        "\n",
        "K Means clustering is an unsupervised machine learning algorithm. Given the number of clusters k, items are grouped together around them.\n",
        "\n",
        "## Bag of words\n",
        " One area of application is text similarity. For instance, given a query string, you want to find the most \"relevant\" document and one way to quantify the relevancy is text similarity. To compute the text similarity, each document is turned into a dictionary array of word frequency. This is called \"the bag of words\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYuoBMEpjzU-"
      },
      "source": [
        "For instance, if we have these words in the vocabulary,\n",
        "\n",
        "['hello', 'is', 'one', 'test', 'this', 'world']\n",
        "\n",
        "the sentence: \"This is one test\" is turned into:\n",
        "\n",
        "[0 1 1 1 1 0]\n",
        "\n",
        "if we mark each word in the vocabulary that appears in the sentence as 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfgAHCiFjw7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1801e7bf-332f-42e3-f271-eb1366e3e04f"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "test_world = [\"this is one test hello world\"]\n",
        "\n",
        "test_vectorizer = CountVectorizer()\n",
        "test_vectorizer.fit(test_world)\n",
        "test = test_vectorizer.transform([\"this is one test\"])\n",
        "hello = test_vectorizer.transform([\"hello world\"])\n",
        "\n",
        "print(test.toarray(), hello.toarray())\n",
        "print(test_vectorizer.get_feature_names())\n",
        "\n",
        "np.dot(test.toarray().reshape(-1), hello.toarray().reshape(-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 1 1 1 0]] [[1 0 0 0 0 1]]\n",
            "['hello', 'is', 'one', 'test', 'this', 'world']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9rDrkYTotXP"
      },
      "source": [
        "## Cosine similarity\n",
        "In the text book, it introduces \"normalized scalar product\" to measure distance of two texts. The formula is:\n",
        "\n",
        "$$ cos\\theta = \\frac{xy}{|x||y|} $$\n",
        "\n",
        "This is called the cosine similarity because it tells you the difference between two normalized vectors. The bigger the number is the more similar. If there is no similarity, they are orthogonal and the result is zero.\n",
        "\n",
        "\n",
        "By flipping the nominator and the denominator, we can use it as a distance measure:\n",
        "\n",
        "$$ d(x, y) = \\frac{|x||y|}{xy} $$\n",
        "\n",
        "In this case, the smaller the number is, the more similar. This is the formula we can use to solve Exercise 8.21"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dIcfPrYnwoj"
      },
      "source": [
        "## Exercise 8.21\n",
        "\n",
        "Exercise 8.21 Determine the distances ds (scalar product) of the following texts to each other.\n",
        "- x1: We will introduce the application of naive Bayes to text analysis on a short example text by Alan Turing from [Tur50].\n",
        "- x2: We may hope that machines will eventually compete with men in all purely intellectual fields. But which are the best ones to start with?\n",
        "- x3: Again I do not know what the right answer is, but I think both approaches should be tried.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PBeNtsKdfV3"
      },
      "source": [
        "x1 = [\"We will introduce the application of naive Bayes to text analysis on a short example text by Alan Turing from [Tur50].\"]\n",
        "x2 = [\"We may hope that machines will eventually compete with men in all purely intellectual fields. But which are the best ones to start with?\"]\n",
        "x3 = [\"Again I do not know what the right answer is, but I think both approaches should be tried.\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7zxw5UhASs3"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(x1 + x2 + x3)\n",
        "t1 = vectorizer.transform(x1)\n",
        "t2 = vectorizer.transform(x2)\n",
        "t3 = vectorizer.transform(x3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJY7CQc1ZoxM"
      },
      "source": [
        "a1 = t1.toarray().reshape(-1)\n",
        "a2 = t2.toarray().reshape(-1)\n",
        "a3 = t3.toarray().reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QhNoPsIaY2O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fccfa2e-1a87-4f79-e377-461975987669"
      },
      "source": [
        "x1x2 = np.dot(a1, a2)\n",
        "x2x3 = np.dot(a2, a3)\n",
        "x1x3 = np.dot(a1, a3)\n",
        "print(\"x1x2\", x1x2)\n",
        "print(\"x2x3\", x2x3)\n",
        "print(\"x1x3\", x1x3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x1x2 4\n",
            "x2x3 2\n",
            "x1x3 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTL1iPLQgVP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70aef9ad-9ef4-488a-d601-8b7404283fe4"
      },
      "source": [
        "x1_norm = np.dot(a1, a1)\n",
        "x2_norm = np.dot(a2, a2)\n",
        "x3_norm = np.dot(a3, a3)\n",
        "print(\"|x1|\", x1_norm)\n",
        "print(\"|x2|\", x2_norm)\n",
        "print(\"|x3|\", x3_norm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|x1| 22\n",
            "|x2| 26\n",
            "|x3| 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9mNrInMdYYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8e57d7-dbce-4e9b-b88c-90545980e9ce"
      },
      "source": [
        "x1x2_sim = np.sqrt(x1_norm*x2_norm)/x1x2\n",
        "x2x3_sim = np.sqrt(x2_norm*x3_norm)/x2x3\n",
        "x1x3_sim = np.sqrt(x1_norm*x3_norm)/x1x3\n",
        "print(\"x1,x2 similarity\", x1x2_sim)\n",
        "print(\"x2,x3 similarity\", x2x3_sim)\n",
        "print(\"x1,x3 similarity\", x1x3_sim)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x1,x2 similarity 5.979130371550699\n",
            "x2,x3 similarity 10.198039027185569\n",
            "x1,x3 similarity 18.76166303929372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9Dxz-FtepAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d71c1b-7793-403c-d070-b858d93f3148"
      },
      "source": [
        "x1x2_sim = x1x2/np.sqrt(x1_norm*x2_norm)\n",
        "x2x3_sim = x2x3/np.sqrt(x2_norm*x3_norm)\n",
        "x1x3_sim = x1x3/np.sqrt(x1_norm*x3_norm)\n",
        "print(\"x1,x2 similarity\", x1x2_sim)\n",
        "print(\"x2,x3 similarity\", x2x3_sim)\n",
        "print(\"x1,x3 similarity\", x1x3_sim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x1,x2 similarity 0.16724840200141816\n",
            "x2,x3 similarity 0.09805806756909202\n",
            "x1,x3 similarity 0.053300179088902604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmh2WPA8oFuj"
      },
      "source": [
        "# Bag of Words from scratch\n",
        "Here is the code that implements the BOW (bag of words) process (taken from https://gist.github.com/edubey/c52a3b34541456a76a2c1f81eebb5f67)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07_O0YmsD_zq"
      },
      "source": [
        "import numpy\n",
        "import re\n",
        "def tokenize(sentences):\n",
        "    words = []\n",
        "    for sentence in sentences:\n",
        "        w = word_extraction(sentence)\n",
        "        words.extend(w)\n",
        "        \n",
        "    words = sorted(list(set(words)))\n",
        "    return words\n",
        "\n",
        "def word_extraction(sentence):\n",
        "    # ignore = ['a', \"the\", \"is\"]\n",
        "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
        "    # cleaned_text = [w.lower() for w in words if w not in ignore]\n",
        "    # return cleaned_text\n",
        "    return words\n",
        "    \n",
        "def generate_bow(allsentences):\n",
        "  vectors = []\n",
        "  vocab = tokenize(allsentences)\n",
        "  print(\"Word List for Document \\n{0} \\n\".format(vocab));\n",
        "\n",
        "  for sentence in allsentences:\n",
        "      words = word_extraction(sentence)\n",
        "      bag_vector = numpy.zeros(len(vocab))\n",
        "      for w in words:\n",
        "          for i,word in enumerate(vocab):\n",
        "              if word == w: \n",
        "                  bag_vector[i] += 1\n",
        "                  \n",
        "      print(\"{0} \\n{1}\\n\".format(sentence,numpy.array(bag_vector)))\n",
        "      vectors.append(bag_vector)\n",
        "  return vocab, vectors\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Sn7rFOFLGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3f8751-9e5e-4a06-de2c-5d1c90470ce2"
      },
      "source": [
        "vocab, bow = generate_bow(x1 + x2 + x3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word List for Document \n",
            "['Again', 'Alan', 'Bayes', 'But', 'I', 'Tur50', 'Turing', 'We', 'a', 'all', 'analysis', 'answer', 'application', 'approaches', 'are', 'be', 'best', 'both', 'but', 'by', 'compete', 'do', 'eventually', 'example', 'fields', 'from', 'hope', 'in', 'intellectual', 'introduce', 'is', 'know', 'machines', 'may', 'men', 'naive', 'not', 'of', 'on', 'ones', 'purely', 'right', 'short', 'should', 'start', 'text', 'that', 'the', 'think', 'to', 'tried', 'what', 'which', 'will', 'with'] \n",
            "\n",
            "We will introduce the application of naive Bayes to text analysis on a short example text by Alan Turing from [Tur50]. \n",
            "[0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 2. 0. 1.\n",
            " 0. 1. 0. 0. 0. 1. 0.]\n",
            "\n",
            "We may hope that machines will eventually compete with men in all purely intellectual fields. But which are the best ones to start with? \n",
            "[0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0.\n",
            " 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 0. 1. 1. 2.]\n",
            "\n",
            "Again I do not know what the right answer is, but I think both approaches should be tried. \n",
            "[1. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 0.]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlbdbDhMFRYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ce8bee2-8581-463c-8b24-20b593ab7725"
      },
      "source": [
        "v1.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5jakAtqFgpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465a28a4-37dd-4d08-e8aa-0a22877eea9c"
      },
      "source": [
        "bow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
              "        0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 2., 0., 1., 0., 1., 0.,\n",
              "        0., 0., 1., 0.]),\n",
              " array([0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "        0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
              "        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
              "        0., 1., 1., 2.]),\n",
              " array([1., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "        1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
              "        1., 0., 0., 0.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZqiUkSWF0Wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c60cc7-bf10-4a0e-850c-1f345459b4d7"
      },
      "source": [
        "bow[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 2., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziQuy7mQGiaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a21101a-f257-47ec-9fd3-02cc0e9891c2"
      },
      "source": [
        "bow[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
              "       0., 1., 1., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ezW37VrGjr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7d7325-d9e6-45b0-f38b-bb2d1b048b77"
      },
      "source": [
        "np.dot(bow[0], bow[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jIiN6YhGnwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab46f746-bde7-414e-9082-fcb5ac60d922"
      },
      "source": [
        "np.dot(bow[1], bow[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qKZPkF3HEeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b8d419-6582-43dc-8c30-1e23642e6c8a"
      },
      "source": [
        "np.dot(bow[0], bow[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DITtAQMyHGrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38062a57-7717-477a-a26b-0a707ac0711f"
      },
      "source": [
        "np.matmul(bow[0], bow[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaAyIsljHQup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3cf3995-ab08-4aff-d447-dd10415b96c9"
      },
      "source": [
        "bow[0].shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yppQITqvI7d9"
      },
      "source": [
        "ids = bow[1] > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrEDhYa8JPP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2881c7be-7130-414e-af93-582a6e3b6ba9"
      },
      "source": [
        "np.where(ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 3,  7,  9, 14, 16, 20, 22, 24, 26, 27, 28, 32, 33, 34, 39, 40, 44,\n",
              "        46, 47, 49, 52, 53, 54]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1eNr_UXLWkx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
